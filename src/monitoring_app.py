import streamlit as st
import pandas as pd
import numpy as np
import time
import threading
from datetime import datetime
import joblib
from keras.models import load_model

# Import c√°c module t·ª± vi·∫øt
from src.utils import TIME_FEATURES, STAT_FEATURES, MODEL_PATH, SCALER_TIME_PATH, SCALER_STAT_PATH, LABEL_ENCODER_PATH
from src.real_log_collector import RealNetworkLogCollector
from src.mock_data_generator import MockNetworkFlowGenerator

# --- C·∫§U H√åNH LOGGING ---
import logging
logging.getLogger("scapy.runtime").setLevel(logging.ERROR)

# ==================== CACHED RESOURCES ====================
# D√πng cache_resource ƒë·ªÉ ƒë·∫£m b·∫£o Collector ch·ªâ kh·ªüi t·∫°o 1 l·∫ßn duy nh·∫•t (Singleton)
@st.cache_resource
def get_traffic_collector(interface_name):
    collector = RealNetworkLogCollector(interface=interface_name)
    return collector

class RealtimeMonitor:
    def __init__(self):
        """Kh·ªüi t·∫°o h·ªá th·ªëng monitoring"""
        try:
            self.model = load_model(MODEL_PATH)
            self.scaler_time = joblib.load(SCALER_TIME_PATH)
            self.scaler_stat = joblib.load(SCALER_STAT_PATH)
            self.le = joblib.load(LABEL_ENCODER_PATH)
            
            # Mock generator cho ch·∫ø ƒë·ªô Demo
            # (Gi·∫£ s·ª≠ b·∫°n c√≥ class n√†y trong src.utils ho·∫∑c file ri√™ng)
            from src.mock_data_generator import MockNetworkFlowGenerator 
            self.data_generator = MockNetworkFlowGenerator()
        except Exception as e:
            st.error(f"L·ªói load model/scaler: {e}")
            st.stop()

        # C·∫•u h√¨nh m·ª©c ƒë·ªô nguy hi·ªÉm
        self.attack_severity = {
            'DDoS': 'HIGH', 'DoS Hulk': 'HIGH', 'DoS GoldenEye': 'HIGH',
            'Bot': 'HIGH', 'Web Attack ‚Äì Brute Force': 'HIGH',
            'Web Attack ‚Äì Sql Injection': 'HIGH', 'Web Attack ‚Äì XSS': 'HIGH',
            'Heartbleed': 'HIGH', 'Infiltration': 'HIGH',
            'PortScan': 'MEDIUM', 'FTP-Patator': 'MEDIUM', 'SSH-Patator': 'MEDIUM',
            'DoS slowloris': 'LOW', 'DoS Slowhttptest': 'LOW',
            'BENIGN': 'SAFE'
        }

    def _align_features(self, df):
        """
        ƒê·∫£m b·∫£o DataFrame c√≥ ƒë√∫ng 22 c·ªôt features theo th·ª© t·ª± training
        """
        required_cols = TIME_FEATURES + STAT_FEATURES
        
        # 1. T·∫°o c√°c c·ªôt thi·∫øu (ƒëi·ªÅn 0)
        for col in required_cols:
            if col not in df.columns:
                df[col] = 0.0
                
        # 2. Ch·ªâ l·∫•y ƒë√∫ng c√°c c·ªôt c·∫ßn thi·∫øt theo th·ª© t·ª±
        return df[required_cols]

    def predict_on_flow(self, flow_data):
        """D·ª± ƒëo√°n tr√™n m·ªôt network flow"""
        try:
            # Chu·∫©n h√≥a c·ªôt d·ªØ li·ªáu (Align features)
            flow_data = self._align_features(flow_data)

            # Tr√≠ch xu·∫•t features
            X_time = flow_data[TIME_FEATURES].values
            X_stat = flow_data[STAT_FEATURES].values
            
            # Normalize b·∫±ng Scaler ƒë√£ train
            X_time = self.scaler_time.transform(X_time)
            X_stat = self.scaler_stat.transform(X_stat)
            
            # Reshape cho LSTM (Samples, Timesteps, Features)
            # Gi·∫£ s·ª≠ TIME_FEATURES training shape l√† (None, 1, n_features)
            X_time = X_time.reshape(X_time.shape[0], 1, X_time.shape[1])
            
            # D·ª± ƒëo√°n
            probs = self.model.predict([X_time, X_stat], verbose=0)
            
            # X·ª≠ l√Ω k·∫øt qu·∫£
            risk_score = np.max(probs[0])
            class_idx = np.argmax(probs[0])
            attack_name = self.le.inverse_transform([class_idx])[0]
            severity = self.attack_severity.get(attack_name, 'UNKNOWN')
            
            # Logic gi·∫£m nhi·ªÖu: N·∫øu ƒë·ªô tin c·∫≠y th·∫•p -> Benign
            if risk_score < 0.6 and attack_name != 'BENIGN':
                attack_name = 'BENIGN (Low Conf)'
                severity = 'SAFE'

            return {
                'attack_name': attack_name,
                'risk_score': float(risk_score),
                'severity': severity,
                'src_ip': flow_data.get('src_ip', 'Unknown'), # L·∫•y IP n·∫øu c√≥
                'dst_ip': flow_data.get('dst_ip', 'Unknown')
            }
        except Exception as e:
            return {
                'attack_name': 'ERROR', 'risk_score': 0.0, 
                'severity': 'ERROR', 'error': str(e)
            }

    def calculate_overall_risk(self, results):
        if not results: return 0.0
        attacks = [r for r in results if r['severity'] in ['HIGH', 'MEDIUM', 'LOW']]
        if not attacks: return 0.0
        avg_risk = np.mean([r['risk_score'] for r in attacks])
        # C√¥ng th·ª©c: T·ªâ l·ªá attack * ƒë·ªô tin c·∫≠y * h·ªá s·ªë khu·∫øch ƒë·∫°i
        risk_percentage = min(100, (len(attacks) / len(results)) * 100 * avg_risk * 1.5)
        return risk_percentage

def create_monitoring_dashboard():
    st.set_page_config(page_title="Network Security Monitoring", page_icon="üõ°Ô∏è", layout="wide")
    st.title("üõ°Ô∏è AI-Powered Network Monitoring System")
    st.markdown("---")

    # ==================== SIDEBAR CONFIG ====================
    with st.sidebar:
        st.header("‚öôÔ∏è System Configuration")
        
        # 1. Ch·ªçn ch·∫ø ƒë·ªô ngu·ªìn d·ªØ li·ªáu
        data_source = st.radio(
            "Data Source",
            ("üõ°Ô∏è Real-time Interface", "üé≤ Mock Data (Demo)"),
            index=0
        )
        
        interface_name = "Wi-Fi" # Gi√° tr·ªã m·∫∑c ƒë·ªãnh
        
        if "Real-time" in data_source:
            # Nh·∫≠p t√™n card m·∫°ng (QUAN TR·ªåNG)
            interface_name = st.text_input(
                "Network Interface Name", 
                value="Wi-Fi",
                help="D√πng l·ªánh 'ipconfig' ho·∫∑c 'show_interfaces()' c·ªßa scapy ƒë·ªÉ l·∫•y t√™n ƒë√∫ng."
            )
            st.info(f"Listening on: {interface_name}")
            
            update_interval = st.slider("Update Interval (s)", 1, 5, 2)
            
        else:
            # C·∫•u h√¨nh cho Mock Data
            batch_size = st.slider("Batch Size", 1, 20, 5)
            update_interval = st.slider("Update Interval (s)", 1, 5, 3)
            attack_dist_type = st.selectbox("Attack Pattern", ["Normal (80% Benign)", "Under Attack (High Risk)"])

        st.markdown("---")
        
        # C√°c n√∫t ƒëi·ªÅu khi·ªÉn
        col_btn1, col_btn2 = st.columns(2)
        with col_btn1:
            start_btn = st.button("‚ñ∂Ô∏è START", type="primary", use_container_width=True)
        with col_btn2:
            stop_btn = st.button("‚èπÔ∏è STOP", use_container_width=True)
        
        reset_btn = st.button("üîÑ Reset History", use_container_width=True)

    # ==================== SESSION STATE INIT ====================
    if 'monitoring_active' not in st.session_state: st.session_state.monitoring_active = False
    if 'start_time' not in st.session_state: st.session_state.start_time = datetime.now()
    if 'history_risk' not in st.session_state: st.session_state.history_risk = []
    if 'alerts' not in st.session_state: st.session_state.alerts = []
    if 'total_flows' not in st.session_state: st.session_state.total_flows = 0
    if 'attack_counts' not in st.session_state: st.session_state.attack_counts = 0

    # Logic n√∫t b·∫•m
    if start_btn:
        st.session_state.monitoring_active = True
        if "Real-time" in data_source:
            # Kh·ªüi ƒë·ªông Collector th·∫≠t
            collector = get_traffic_collector(interface_name)
            if not collector.sniff_thread or not collector.sniff_thread.is_alive():
                collector.start()
            st.toast(f"Started sniffing on {interface_name}")
            
    if stop_btn:
        st.session_state.monitoring_active = False
        if "Real-time" in data_source:
            collector = get_traffic_collector(interface_name)
            collector.stop()
            st.toast("Stopped sniffing")

    if reset_btn:
        st.session_state.history_risk = []
        st.session_state.alerts = []
        st.session_state.total_flows = 0
        st.session_state.attack_counts = 0
        st.session_state.start_time = datetime.now()
        st.experimental_rerun()

    # ==================== MAIN METRICS UI ====================
    col1, col2, col3, col4 = st.columns(4)
    
    # T√≠nh to√°n th·ªùi gian ch·∫°y
    elapsed = datetime.now() - st.session_state.start_time
    elapsed_str = str(elapsed).split('.')[0]
    
    # L·∫•y gi√° tr·ªã risk m·ªõi nh·∫•t
    current_risk = st.session_state.history_risk[-1] if st.session_state.history_risk else 0
    
    # M√†u tr·∫°ng th√°i
    if current_risk > 75: state_color, state_text = "red", "CRITICAL"
    elif current_risk > 40: state_color, state_text = "orange", "WARNING"
    else: state_color, state_text = "green", "SAFE"

    col1.metric("‚è±Ô∏è Monitor Duration", elapsed_str)
    col2.metric("üìä Current Risk", f"{current_risk:.1f}%", delta=None)
    col3.metric("‚ö° Total Attacks", st.session_state.attack_counts)
    col4.markdown(f"#### Status: :{state_color}[{state_text}]")

    # ==================== PROCESSING ENGINE ====================
    monitor = RealtimeMonitor()
    
    # Placeholder cho UI update
    chart_place = st.empty()
    alert_place = st.empty()
    
    if st.session_state.monitoring_active:
        new_flows_df = pd.DataFrame()
        
        # 1. THU TH·∫¨P D·ªÆ LI·ªÜU
        if "Real-time" in data_source:
            # L·∫•y d·ªØ li·ªáu t·ª´ Collector th·∫≠t
            collector = get_traffic_collector(interface_name)
            new_flows_df = collector.get_new_flows()
        else:
            # L·∫•y d·ªØ li·ªáu gi·∫£ l·∫≠p
            dist = {'BENIGN': 0.8} if "Normal" in attack_dist_type else {'BENIGN': 0.2, 'DDoS': 0.8}
            new_flows_df = monitor.data_generator.generate_batch_flows(batch_size, dist)

        # 2. X·ª¨ L√ù N·∫æU C√ì D·ªÆ LI·ªÜU
        if not new_flows_df.empty:
            st.session_state.total_flows += len(new_flows_df)
            batch_results = []
            
            for idx, row in new_flows_df.iterrows():
                # Predict t·ª´ng flow
                # Chuy·ªÉn row th√†nh DataFrame 1 d√≤ng ƒë·ªÉ gi·ªØ t√™n c·ªôt
                single_flow = new_flows_df.iloc[[idx]]
                result = monitor.predict_on_flow(single_flow)
                batch_results.append(result)
                
                # Update counters & Alerts
                if result['severity'] in ['HIGH', 'MEDIUM']:
                    st.session_state.attack_counts += 1
                    timestamp = datetime.now().strftime("%H:%M:%S")
                    
                    # T·∫°o th√¥ng b√°o IP n·∫øu c√≥
                    ip_info = ""
                    if 'src_ip' in result and isinstance(result['src_ip'], str):
                         ip_info = f" | {result['src_ip']} -> {result['dst_ip']}"

                    msg = f"[{timestamp}] üö® {result['attack_name']} Detected (Risk: {result['risk_score']:.2f}){ip_info}"
                    st.session_state.alerts.insert(0, msg) # Th√™m v√†o ƒë·∫ßu danh s√°ch

            # T√≠nh to√°n Risk t·ªïng th·ªÉ c·ªßa batch n√†y
            batch_risk = monitor.calculate_overall_risk(batch_results)
            st.session_state.history_risk.append(batch_risk)
            
            # Gi·ªõi h·∫°n l·ªãch s·ª≠ bi·ªÉu ƒë·ªì
            if len(st.session_state.history_risk) > 100:
                st.session_state.history_risk.pop(0)
                
            # Log ra m√†n h√¨nh console (optional)
            # print(f"Processed {len(new_flows_df)} flows. Risk: {batch_risk:.2f}%")
            
        else:
            # N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu th·∫≠t, l·∫∑p l·∫°i risk c≈© ƒë·ªÉ bi·ªÉu ƒë·ªì ch·∫°y ti·∫øp
            if st.session_state.history_risk:
                st.session_state.history_risk.append(st.session_state.history_risk[-1] * 0.95) # Gi·∫£m d·∫ßn risk n·∫øu im l·∫∑ng

        # 3. T·ª∞ ƒê·ªòNG REFRESH
        time.sleep(update_interval)
        st.rerun()

    # ==================== VISUALIZATION ====================
    
    # Bi·ªÉu ƒë·ªì Real-time
    with chart_place.container():
        st.subheader("üìà Network Threat Level (Real-time)")
        if st.session_state.history_risk:
            chart_data = pd.DataFrame(st.session_state.history_risk, columns=["Risk Percentage"])
            st.line_chart(chart_data, height=250)
        else:
            st.info("Waiting for traffic data...")

    # Khu v·ª±c c·∫£nh b√°o & Chi ti·∫øt
    col_log, col_detail = st.columns([1, 1])
    
    with col_log:
        st.subheader("üö® Security Alerts Log")
        alert_container = st.container(height=300)
        if st.session_state.alerts:
            for alert in st.session_state.alerts[:20]: # Hi·ªÉn th·ªã 20 alert m·ªõi nh·∫•t
                if "HIGH" in alert or "CRITICAL" in alert: # Logic m√†u m√®
                    alert_container.error(alert)
                else:
                    alert_container.warning(alert)
        else:
            alert_container.success("No security threats detected recently.")

    with col_detail:
        st.subheader("üìã Last Captured Batch Details")
        if st.session_state.monitoring_active and 'new_flows_df' in locals() and not new_flows_df.empty:
            # Hi·ªÉn th·ªã b·∫£ng r√∫t g·ªçn
            display_cols = ['src_ip', 'dst_ip', 'proto', 'Flow Duration']
            # L·ªçc c√°c c·ªôt t·ªìn t·∫°i ƒë·ªÉ tr√°nh l·ªói
            valid_cols = [c for c in display_cols if c in new_flows_df.columns]
            
            # Th√™m c·ªôt d·ª± ƒëo√°n v√†o ƒë·ªÉ xem
            display_df = new_flows_df[valid_cols].copy()
            if 'batch_results' in locals():
                display_df['Prediction'] = [r['attack_name'] for r in batch_results]
            
            st.dataframe(display_df.head(10), use_container_width=True)
        else:
            st.text("No active flows in current buffer.")

if __name__ == "__main__":
    create_monitoring_dashboard()